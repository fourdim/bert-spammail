{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam/Ham Email Classification using BERT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TensorFlow Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "CSV_COLUMNS = ['id', 'subject', 'email']\n",
    "LABEL_COLUMN = 'spam'\n",
    "\n",
    "def get_dataset(file_path):\n",
    "  dataset = tf.data.experimental.make_csv_dataset(\n",
    "      file_path,\n",
    "      batch_size=12,\n",
    "      label_name=LABEL_COLUMN,\n",
    "      na_value=\"?\",\n",
    "      num_epochs=1,\n",
    "      ignore_errors=True)\n",
    "  return dataset\n",
    "\n",
    "ds_train = pd.read_csv('data/train.csv')\n",
    "ds_test = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text_batch, label_batch in ds_train.take(1):\n",
    "#   for i in range(2):\n",
    "#     print(f'Subject: {text_batch[\"subject\"][i]}')\n",
    "#     print(f'Email: {text_batch[\"email\"][i]}')\n",
    "#     print(f'Label : {label_batch[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    email_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='email')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(email_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(email_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " email (InputLayer)             [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_word_ids':   0           ['email[0][0]']                  \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'sequence_output':  28763649    ['preprocessing[0][0]',          \n",
      "                                 (None, 128, 512),                'preprocessing[0][1]',          \n",
      "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                512)}                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,) <dtype: 'string'>\n",
      "(None, 1) <dtype: 'float32'>\n",
      "email [(None,)] string\n",
      "preprocessing None float32\n",
      "BERT_encoder {'input_word_ids': (None, 128), 'input_type_ids': (None, 128), 'input_mask': (None, 128)} float32\n",
      "dropout_1 (None, 512) float32\n",
      "classifier (None, 512) float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.shape, i.dtype) for i in classifier_model.inputs]\n",
    "[print(o.shape, o.dtype) for o in classifier_model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in classifier_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "epochs = 5\n",
    "steps_per_epoch = len(ds_train) // 12\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train['subject'] = ds_train['subject'].astype(str)\n",
    "ds_train['email'] = ds_train['email'].astype(str)\n",
    "ds_train_email = ds_train.agg('{0[subject]} {0[email]}'.format, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 69s 310ms/step - loss: 0.2829 - binary_accuracy: 0.8669\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 62s 297ms/step - loss: 0.0684 - binary_accuracy: 0.9777\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 62s 295ms/step - loss: 0.0353 - binary_accuracy: 0.9901\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 61s 290ms/step - loss: 0.0181 - binary_accuracy: 0.9942\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 63s 299ms/step - loss: 0.0067 - binary_accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = classifier_model.fit(x=ds_train_email,\n",
    "                               y=ds_train['spam'],\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject: Wired: \"Stronger ties between ISPs and file-trading companies\\n URL: http://scriptingnews.userland.com/backissues/2002/09/25#When:8:33:10AM\\n Date: Wed, 25 Sep 2002 15:33:10 GMT\\n \\n Wired[1]: \"Stronger ties between ISPs and file-trading companies could bolster \\n Kazaa\\'s defenses.\"\\n \\n [1] http://www.wired.com/news/mp3/0,1285,55356,00.html\\n \\n \\n'\n",
      " 'Subject: One of a kind Money maker! Try it for free!\\n ------000000000000000000000\\n Content-Type: text/html;\\n \\tcharset=\"iso-8859-1\"\\n Content-Transfer-Encoding: 7bit\\n \\n <body lang=EN-US>\\n \\n <div class=Section1>\\n \\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'><b>CONSANTLY</b> being\\n bombarded by so-called FREE money-making systems that teases you with limited\\n information, and when its all said and done, blind-sides you by demanding your\\n money/credit card information upfront in some slick way,<b> after-the-fact</b>!\\n Yes, I too was as skeptical about such offers and the Internet in general with\\n all its hype, as you probably are. Fortunate for me, my main business\\n slowed-down (<i>I have been self-employed all my life</i>), so I looked for\\n something to fit my lifestyle and some other way to assist me in paying my\\n bills, without working myself to death or loosing more money; then, this\\n proposal to try something new without any upfront investment (<i>great! because\\n I had none</i>) interested me to click on the link provided. And I dont regret\\n at all that I did! I am very happy, and happy enough to recommend it to you as\\n a system that is true to its word. I mean absolutely no upfront money. You join\\n only if (<i>when</i>) you make money. You also get to track the results of your\\n time and efforts instantly and updated daily! I especially liked this idea of\\n personal control with real-time, staying informed statistics.</p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'><b>This system is quite simply\\n the most logical, opened, and fair of any others that Ive seen before. Why?\\n Because from the start, you get all the specific facts you need to seriously\\n consider if this is right for you. No teasing. No grand testimonies! No\\n kidding! Just the facts! Unlike in other programs that give you no idea of\\n their overall plan before first forking over your money/credit card; or worst\\n yet, joining and finding-out too late, after wasting valuable time trying to\\n figure them out, this system is straightforward and informative, providing you\\n with the two things you really must know: <u>Whats it all about</u>? and <u>How\\n does it work</u>?. These are the ultimate deal makers or deal breakers that\\n need to be immediately disclosed, well before discovering that maybe you dont\\n want to do that; by then you are hooked and now locked into a frustrating\\n battle to try to get your money back! </b></p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'>I call this my Platinum\\n Choice because it stands alone as a true, superior deal that is totally\\n different from previously misleading, hook-first programs that promise lofty\\n mega-money jackpots, but really just want your money upfront to line their own\\n pockets! Youve seen the headlines: <u>Join free and Make $10,000 every week\\n for life</u> yeah, right!</p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'>I did not make millions yet,\\n but the whole thing was launched just a few weeks ago and I am more than happy\\n with my earnings, so far. I must tell you, I wouldnt be able to do anything\\n without corporate help  which was unusually thorough, timely, and motivating. </p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'>You have to see this in action\\n for yourself and make up your own mind; just go to my site and fill out the\\n form as soon as you can. You will get your own site in a few minutes. Then you\\n are ready to try whether you can make some decent money with this system and\\n the Internets explosive potential - fully loaded with hi-tech software, free\\n corporate help, on-time members support and even protective safeguards! </p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'>Get it now, and you can call me\\n at any time with questions. It really could help you like it is helping me to\\n finally be able to pay my bills, and keep my free time free. Good luck!</p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'><a\\n href=\"http://www.mindupmerchants.com/default.asp?ID=5581\">http://www.mindupmerchants.com/default.asp?ID=5581</a></p>\\n \\n <p class=MsoBodyText style=\\'text-align:justify\\'>Ben Green, (775) 322-3323 </p>\\n \\n <p class=MsoBodyText>P.S.Free POP3 email is ofered for members now!</p>\\n </div>\\n \\n </body>\\n \\n ------000000000000000000000--\\n'\n",
      " \"Subject: Re: Entrepreneurs\\n There's been well documented articles, studies of the\\n French tax laws, corporate governance, and financial\\n oversight that 1) dont' easily allow for ISOs, the root\\n of almost all entrepreneurialship, and 2) the easy flow\\n of capital to new ventures.  It was an extremely large\\n issue, even debated widely in France.\\n \\n Greg\\n \\n Chuck Murcko wrote:\\n \\n > According to my son, it was actually Homer Simpson, who claimed the \\n > French had no word for victory.\\n > \\n > Chuck\\n > \\n > On Thursday, August 22, 2002, at 01:58 PM, Robert Harley wrote:\\n > \\n >> An apparent quote from Dubya, from the Times (sent to me by my Dad):\\n >>\\n >> http://www.timesonline.co.uk/printFriendly/0,,1-43-351083,00.html\\n >>\\n >> ------------------------------------------------------------------------------ \\n >>\\n >> TONY BLAIR's special relationship with George W. Bush is under\\n >> considerable strain. Not only do the two disagree on Yassir Arafat's\\n >> tenure as leader of the Palestinian Authority, but Blair has started\\n >> telling disparaging anecdotes about the President.\\n >>\\n >> Baroness Williams of Crosby recalled a story told to her by 'my good\\n >> friend Tony Blair' recently in Brighton. Blair, Bush and Jacques\\n >> Chirac were discussing economics and, in particular, the decline of\\n >> the French economy. 'The problem with the French,' Bush confided in\\n >> Blair, 'is that they don't have a word for entrepreneur.'\\n >> ------------------------------------------------------------------------------ \\n >>\\n >>\\n >> R\\n >> http://xent.com/mailman/listinfo/fork\\n >>\\n > \\n > http://xent.com/mailman/listinfo/fork\\n > \\n \\n \\n \\n http://xent.com/mailman/listinfo/fork\\n \\n\"\n",
      " 'Subject: [IIU] Viruses and Bounced Mail\\n All,\\n \\n Is it just me or has there been a massive increase in the amount of email \\n being falsely bounced around the place? I\\'ve already received email from a \\n number of people I don\\'t know, asking why I am sending them email. These \\n can be explained by servers from Russia and elsewhere. Coupled with the \\n false emails I received myself, it\\'s really starting to annoy me. Am I the \\n only one seeing an increase in recent weeks?\\n \\n Martin\\n \\n \\n \\n ========================================================================\\n Martin Whelan | Dise Design | www.deisedesign.com | Tel : 086-8888975\\n \\n \" Our core product Diseditor  allows organisations to publish information \\n to their web site in a fast and cost effective manner. There is no need for \\n a full time web developer, as the site can be easily updated by the \\n organisations own staff.\\n Instant updates to keep site information fresh. Sites which are updated \\n regularly bring users back. Visit www.deisedesign.com/deiseditor.html for a \\n demonstration \"\\n \\n Diseditor  \" Managing Your Information \"\\n ========================================================================\\n \\n _______________________________________________\\n IIU mailing list\\n IIU@iiu.taint.org\\n http://iiu.taint.org/mailman/listinfo/iiu\\n \\n'\n",
      " 'Subject: Free New Cars for the Taking!\\n <html>\\n <body>\\n \\n <center>\\n <font face=\"arial\" size=\"10\">\\n <a href=\"http://ct2.consumertoday.net/cgi-bin14/flo?y=hE10CCzME0D40ER0Ac\">Get a FREE CAR or SUV!<br>\\n CLICK HERE!</a>\\n <br><br>\\n <font size=\"6\">\\n There are hundreds of companies <br>giving away FREE CARS!\\n <br>\\n <br>\\n   <a href=\"http://ct2.consumertoday.net/cgi-bin14/flo?y=hE10CCzME0D40ER0Ac\"> <img src=\"http://www.bd12.com/allfreecars/graph.gif\" border=\"0\"></a> \\n   <br>\\n   <br>\\n <a href=\"http://ct2.consumertoday.net/cgi-bin14/flo?y=hE10CCzME0D40ER0Ac\">Chevy Blazer<br>\\n Dodge Durango<br>\\n Ford Windstar<br>\\n Honda Civic And More...!<br>\\n CLICK HERE!</a><B>\\n \\n <br>\\n </b></font><B>\\n <font face=arial size=1>\\n \\n \\n </font>\\n </b></font></center><BR><BR><CENTER><table border=\"1\" cellpadding=\"3\" cellspacing=\"0\" width=\"550\" bordercolor=\"#000000\" body bgcolor=\"white\">\\n <tr><td width=\"551\" height=\"5\" align=\"center\" valign=\"middle\"><table width=\"550\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\"><tr><td><FONT FACE=\"Verdana, Modern, Arial\" SIZE=\"2\" color=\"gray\">We take your privacy very seriously and it is our policy never to send unwanted email messages. This message has been sent to gibbs@midrange.com because you are a member of Consumer Today or you signed up with one of our marketing partners. To unsubscribe, simply click <a href=\"http://unsub.ct.consumertoday.net/consumer_today/ct_site_unsub.html\"><font color=\"blue\"><u>here</u></font></a> (please allow 3-5 business days for your unsubscribe request to be processed). Questions or comments - send them to <a href=\"mailto:customerservice@consumertoday.net\"><font color=\"blue\"><u>customerservice@consumertoday.net</u></font></a>.</td></tr></table></td></tr></table></font></center></body>\\n \\n <IMG SRC=\"http://ct2.consumertoday.net/cgi-bin14/flosensing?y=E10CCzME0D40BK\"></html>\\n \\n']\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 5 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\workspace\\spammail\\train.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(examples\u001b[39m.\u001b[39mhead()\u001b[39m.\u001b[39mto_numpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m results \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msigmoid(classifier_model(tf\u001b[39m.\u001b[39mconstant(examples\u001b[39m.\u001b[39mhead()\u001b[39m.\u001b[39mto_numpy())))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m print_my_examples(examples, results)\n",
      "\u001b[1;32md:\\workspace\\spammail\\train.ipynb Cell 15\u001b[0m in \u001b[0;36mprint_my_examples\u001b[1;34m(inputs, results)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_my_examples\u001b[39m(inputs, results):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   result_for_printing \u001b[39m=\u001b[39m \\\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{\u001b[39;00minputs[i]\u001b[39m:\u001b[39;00m\u001b[39m<30\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m : score: \u001b[39m\u001b[39m{\u001b[39;00mresults[i][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                          \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputs))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m*\u001b[39mresult_for_printing, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mprint\u001b[39m()\n",
      "\u001b[1;32md:\\workspace\\spammail\\train.ipynb Cell 15\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_my_examples\u001b[39m(inputs, results):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   result_for_printing \u001b[39m=\u001b[39m \\\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{\u001b[39;00minputs[i]\u001b[39m:\u001b[39;00m\u001b[39m<30\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m : score: \u001b[39m\u001b[39m{\u001b[39;00mresults[i][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                          \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputs))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m*\u001b[39mresult_for_printing, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/workspace/spammail/train.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mprint\u001b[39m()\n",
      "File \u001b[1;32md:\\venv\\bert\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\venv\\bert\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 5 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "examples = ds_test.agg('{0[subject]} {0[email]}'.format, axis=1)\n",
    "print(examples.head().to_numpy())\n",
    "results = tf.sigmoid(classifier_model(tf.constant(examples.head())))\n",
    "print_my_examples(examples.head(), results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2eedd1f797abafb6069ebbf0dc6c2950a95d512cf4b73885af6069afbde37881"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
